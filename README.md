# Mini-GPT

![Python](https://img.shields.io/badge/language-Python-blue.svg) ![Repo Size](https://img.shields.io/github/repo-size/PawanKiitb/mini-gpt) ![Last Commit](https://img.shields.io/github/last-commit/PawanKiitb/mini-gpt)

Mini-GPT is a lightweight implementation of a Generative Pre-trained Transformer (GPT) model. It aims to provide a simplified yet effective way to understand and experiment with GPT architectures for natural language processing tasks.

## 🚀 Features

- **Lightweight**: Implements the core concepts of GPT without unnecessary complexity.
- **Educational**: Ideal for learning and experimenting with GPT architectures.
- **Customizable**: Easy to extend and modify for specific use cases.
- **100% Python**: Fully implemented in Python for simplicity and accessibility.

## 📂 Project Structure

```
mini-gpt/
├── data/          # Dataset files
├── models/        # Model architecture
├── training/      # Training scripts
├── utils/         # Utility functions
└── README.md      # Project documentation
```

## 🛠️ Getting Started

### Prerequisites

- Python 3.7+
- pip (Python package manager)

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/PawanKiitb/mini-gpt.git
   ```

2. Navigate to the project directory:

   ```bash
   cd mini-gpt
   ```

3. Install the required dependencies:

   ```bash
   pip install -r requirements.txt
   ```

### Usage

1. Prepare your dataset and place it in the `data/` directory.
2. Train the model:

   ```bash
   python training/train.py
   ```

3. Test the model:

   ```bash
   python testing/test.py
   ```

## 📖 Learn More

- [GPT Paper](https://arxiv.org/abs/2005.14165)
- [Transformer Architecture](https://arxiv.org/abs/1706.03762)

## 🤝 Contribution

Contributions are welcome! Please open an issue or submit a pull request if you have suggestions or improvements.

## 📜 License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

⭐️ If you like this project, give it a star!